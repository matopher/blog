'use strict';

var chalk = require('chalk');
var fs = require('fs');
var logSymbols = require('log-symbols');
var path = require('path');
var _internal = require('./_internal-hHVP4WHZ.js');
var tty = require('tty');
var readPkgUp = require('read-pkg-up');
var worker_threads = require('worker_threads');
var workerChannels = require('./workerChannels-BZhuLtcy.js');
function _interopDefaultCompat(e) {
  return e && typeof e === 'object' && 'default' in e ? e : {
    default: e
  };
}
var chalk__default = /*#__PURE__*/_interopDefaultCompat(chalk);
var fs__default = /*#__PURE__*/_interopDefaultCompat(fs);
var logSymbols__default = /*#__PURE__*/_interopDefaultCompat(logSymbols);
var path__default = /*#__PURE__*/_interopDefaultCompat(path);
var readPkgUp__default = /*#__PURE__*/_interopDefaultCompat(readPkgUp);
async function arrayFromAsync(iterable) {
  const results = [];
  for await (const item of iterable) results.push(item);
  return results;
}
const json = async _ref => {
  let {
    output,
    worker
  } = _ref;
  const results = await arrayFromAsync(worker.stream.validation());
  const formatted = results.filter(_ref2 => {
    let {
      markers
    } = _ref2;
    return markers.length;
  }).map(_ref3 => {
    let {
      validatedCount,
      ...result
    } = _ref3;
    return result;
  });
  await worker.dispose();
  output.print(JSON.stringify(formatted));
  let overallLevel = "info";
  for (const {
    level
  } of formatted) {
    if (level === "error") overallLevel = "error";
    if (level === "warning" && overallLevel !== "error") overallLevel = "warning";
  }
  return overallLevel;
};
const ndjson = async _ref4 => {
  let {
    output,
    worker
  } = _ref4;
  let overallLevel = "info";
  for await (const {
    validatedCount,
    ...result
  } of worker.stream.validation()) {
    if (result.level === "error") overallLevel = "error";
    if (result.level === "warning" && overallLevel !== "error") overallLevel = "warning";
    if (result.markers.length) {
      output.print(JSON.stringify(result));
    }
  }
  await worker.dispose();
  return overallLevel;
};
const isTty = tty.isatty(1);
const levelValues = {
  error: 0,
  warning: 1,
  info: 2
};
const count = (amount, subject) => "".concat(amount.toLocaleString("en-US"), " ").concat(amount === 1 ? subject.substring(0, subject.length - 1) : subject);
const percentageFormatter = new Intl.NumberFormat("en-US", {
  style: "percent",
  minimumFractionDigits: 1,
  maximumFractionDigits: 1
});
const percent = value => percentageFormatter.format(Math.min(value, 1));
const secondFormatter = new Intl.NumberFormat("en-US", {
  minimumFractionDigits: 1,
  maximumFractionDigits: 1
});
const seconds = startTime => {
  const endTime = Date.now();
  return "(".concat(secondFormatter.format((endTime - startTime) / 1e3), "s)");
};
const summary = function (_ref5) {
  let {
    errors,
    infos,
    valid,
    warnings
  } = _ref5;
  let level = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "warning";
  const levelValue = levelValues[level];
  return ["".concat(logSymbols__default.default.success, " Valid:    ").concat(count(valid.documents, "documents")), "".concat(logSymbols__default.default.error, " Errors:   ").concat(count(errors.documents, "documents"), ", ").concat(count(errors.markers, "errors")), levelValue >= levelValues.warning && "".concat(logSymbols__default.default.warning, " Warnings: ").concat(count(warnings.documents, "documents"), ", ").concat(count(warnings.markers, "warnings")), levelValue >= levelValues.info && "".concat(logSymbols__default.default.info, " Info:     ").concat(count(infos.documents, "documents"), ", ").concat(count(infos.documents, "markers"))].filter(Boolean).join("\n");
};
const levelHeaders = {
  error: isTty ? chalk__default.default.bold(chalk__default.default.bgRed(chalk__default.default.black(" ERROR "))) : chalk__default.default.red("[ERROR]"),
  warning: isTty ? chalk__default.default.bold(chalk__default.default.bgYellow(chalk__default.default.black(" WARN "))) : chalk__default.default.yellow("[WARN]"),
  info: isTty ? chalk__default.default.bold(chalk__default.default.cyan(chalk__default.default.black(" INFO "))) : chalk__default.default.cyan("[INFO]")
};
const link = (text, url) => isTty ? "\x1B]8;;".concat(url, "\x07").concat(text, "\x1B]8;;\x07") : chalk__default.default.underline(text);
const compareLevels = (a, b) => levelValues[a.level] - levelValues[b.level];
const formatRootErrors = (root, hasChildren, paddingLength) => {
  if (!root.nodes) return "";
  const [first, ...rest] = root.nodes.slice().sort(compareLevels);
  if (!first) return "";
  const firstElbow = hasChildren ? "\u2502 " : "\u2514\u2500";
  const firstPadding = ".".repeat(paddingLength - 6);
  const firstLine = "".concat(firstElbow, " (root) ").concat(firstPadding, " ").concat(logSymbols__default.default[first.level], " ").concat(first.message);
  const subsequentPadding = " ".repeat(paddingLength + 2);
  const subsequentElbow = hasChildren ? "\u2502 " : "  ";
  const restOfLines = rest.map(marker => "".concat(subsequentElbow).concat(subsequentPadding, " ").concat(logSymbols__default.default[marker.level], " ").concat(marker.message)).join("\n");
  return [firstLine, restOfLines].filter(Boolean).join("\n");
};
function formatDocumentValidation(_ref6) {
  let {
    documentId,
    documentType,
    level,
    markers,
    intentUrl
  } = _ref6;
  const tree = _internal.convertToTree(markers);
  const documentTypeHeader = isTty ? chalk__default.default.bgWhite(chalk__default.default.black(" ".concat(documentType, " "))) : "[".concat(documentType, "]");
  const header = "".concat(levelHeaders[level], " ").concat(documentTypeHeader, " ").concat(intentUrl ? link(documentId, intentUrl) : chalk__default.default.underline(documentId));
  const paddingLength = Math.max(_internal.maxKeyLength(tree.children) + 2, 30);
  const childErrors = _internal.formatTree({
    node: tree.children,
    paddingLength,
    getNodes: _ref7 => {
      let {
        nodes
      } = _ref7;
      return (nodes != null ? nodes : []).slice().sort(compareLevels);
    },
    getMessage: marker => [logSymbols__default.default[marker.level], marker.message].join(" ")
  });
  const rootErrors = formatRootErrors(tree, childErrors.length > 0, paddingLength);
  return [header, rootErrors, childErrors].filter(Boolean).join("\n");
}
const pretty = async _ref8 => {
  let {
    output,
    worker,
    flags
  } = _ref8;
  const workspaceLoadStart = Date.now();
  const spinner = output.spinner(flags.workspace ? "Loading workspace '".concat(flags.workspace, "'\u2026") : "Loading workspace\u2026").start();
  const workspace = await worker.event.loadedWorkspace();
  spinner.succeed("Loaded workspace '".concat(workspace.name, "' using project '").concat(workspace.projectId, "' and dataset '").concat(flags.dataset || workspace.dataset, "' ").concat(seconds(workspaceLoadStart)));
  if (!flags.file) {
    spinner.start("Calculating documents to be validated\u2026");
    const {
      documentCount
    } = await worker.event.loadedDocumentCount();
    const downloadStart = Date.now();
    spinner.text = "Downloading ".concat(count(documentCount, "documents"), "\u2026");
    for await (const {
      downloadedCount
    } of worker.stream.exportProgress()) {
      const percentage = percent(downloadedCount / documentCount);
      spinner.text = "Downloading ".concat(count(documentCount, "documents"), "\u2026 ").concat(percentage);
    }
    spinner.succeed("Downloaded ".concat(count(documentCount, "documents"), " ").concat(seconds(downloadStart)));
  }
  const {
    totalDocumentsToValidate
  } = await worker.event.exportFinished();
  const referenceIntegrityStart = Date.now();
  spinner.start("Checking reference existence\u2026");
  await worker.event.loadedReferenceIntegrity();
  spinner.succeed("Checked all references ".concat(seconds(referenceIntegrityStart)));
  const validationStart = Date.now();
  spinner.start("Validating ".concat(count(totalDocumentsToValidate, "documents"), "\u2026"));
  const results = [];
  const totals = {
    valid: {
      documents: 0
    },
    errors: {
      documents: 0,
      markers: 0
    },
    warnings: {
      documents: 0,
      markers: 0
    },
    infos: {
      documents: 0,
      markers: 0
    }
  };
  for await (const {
    validatedCount,
    ...result
  } of worker.stream.validation()) {
    const {
      markers
    } = result;
    if (markers.length) {
      results.push(result);
    }
    const errors = markers.filter(marker => marker.level === "error");
    const warnings = markers.filter(marker => marker.level === "warning");
    const infos = markers.filter(marker => marker.level === "info");
    if (!markers.length) {
      totals.valid.documents += 1;
    }
    if (errors.length) {
      totals.errors.documents += 1;
      totals.errors.markers += errors.length;
    }
    if (warnings.length) {
      totals.warnings.documents += 1;
      totals.warnings.markers += warnings.length;
    }
    if (infos.length) {
      totals.infos.documents += 1;
      totals.infos.markers += infos.length;
    }
    spinner.text = "Validating ".concat(count(totalDocumentsToValidate, "documents"), "\u2026\n\n") + "Processed ".concat(count(validatedCount, "documents"), " (").concat(percent(validatedCount / totalDocumentsToValidate), "):\n").concat(summary(totals, flags.level));
  }
  spinner.succeed("Validated ".concat(count(totalDocumentsToValidate, "documents"), " ").concat(seconds(validationStart)));
  output.print("\nValidation results:\n".concat(summary(totals, flags.level)));
  results.sort((a, b) => {
    if (a.level === b.level) return a.documentType.localeCompare(b.documentType);
    return levelValues[a.level] - levelValues[b.level];
  });
  let overallLevel = "info";
  for (const result of results) {
    if (result.level === "error") overallLevel = "error";
    if (result.level === "warning" && overallLevel !== "error") overallLevel = "warning";
    output.print("".concat(formatDocumentValidation(result), "\n"));
  }
  await worker.dispose();
  return overallLevel;
};
const reporters = {
  pretty,
  ndjson,
  json
};
const DEFAULT_MAX_CUSTOM_VALIDATION_CONCURRENCY = 5;
const defaultReporter = _ref9 => {
  let {
    stream,
    dispose
  } = _ref9;
  async function* createValidationGenerator() {
    for await (const {
      documentId,
      documentType,
      markers,
      revision,
      level
    } of stream.validation()) {
      const result = {
        documentId,
        documentType,
        revision,
        level,
        markers
      };
      yield result;
    }
    await dispose();
  }
  return createValidationGenerator();
};
function validateDocuments(options) {
  var _a;
  const {
    workspace,
    clientConfig,
    configPath,
    dataset,
    projectId,
    workDir = process.cwd(),
    reporter = defaultReporter,
    level,
    maxCustomValidationConcurrency,
    ndjsonFilePath
  } = options;
  const rootPkgPath = (_a = readPkgUp__default.default.sync({
    cwd: __dirname
  })) == null ? void 0 : _a.path;
  if (!rootPkgPath) {
    throw new Error("Could not find root directory for `sanity` package");
  }
  const workerPath = path__default.default.join(path__default.default.dirname(rootPkgPath), "lib", "_internal", "cli", "threads", "validateDocuments.js");
  const worker = new worker_threads.Worker(workerPath, {
    workerData: {
      workDir,
      // removes props in the config that make this object fail to serialize
      clientConfig: JSON.parse(JSON.stringify(clientConfig)),
      configPath,
      workspace,
      dataset,
      projectId,
      level,
      ndjsonFilePath,
      maxCustomValidationConcurrency: maxCustomValidationConcurrency != null ? maxCustomValidationConcurrency : DEFAULT_MAX_CUSTOM_VALIDATION_CONCURRENCY
    },
    // eslint-disable-next-line no-process-env
    env: process.env
  });
  return reporter(workerChannels.createReceiver(worker));
}
async function validateAction(args, _ref10) {
  let {
    apiClient,
    workDir,
    output,
    prompt
  } = _ref10;
  const flags = args.extOptions;
  const unattendedMode = Boolean(flags.yes || flags.y);
  if (!unattendedMode) {
    output.print("".concat(chalk__default.default.yellow("".concat(logSymbols__default.default.warning, " Warning:")), " This command ").concat(flags.file ? "reads all documents from your input file" : "downloads all documents from your dataset", " and processes them through your local schema within a ") + "simulated browser environment.\n");
    output.print("Potential pitfalls:\n");
    output.print("- Processes all documents locally (excluding assets). Large datasets may require more resources.");
    output.print("- Executes all custom validation functions. Some functions may need to be refactored for compatibility.");
    output.print("- Not all standard browser features are available and may cause issues while loading your Studio.");
    output.print("- Adheres to document permissions. Ensure this account can see all desired documents.");
    if (flags.file) {
      output.print("- Checks for missing document references against the live dataset if not found in your file.");
    }
    const confirmed = await prompt.single({
      type: "confirm",
      message: "Are you sure you want to continue?",
      default: true
    });
    if (!confirmed) {
      output.print("User aborted");
      process.exitCode = 1;
      return;
    }
  }
  if (flags.format && !(flags.format in reporters)) {
    const formatter = new Intl.ListFormat("en-US", {
      style: "long",
      type: "conjunction"
    });
    throw new Error("Did not recognize format '".concat(flags.format, "'. Available formats are ").concat(formatter.format(Object.keys(reporters).map(key => "'".concat(key, "'")))));
  }
  const level = flags.level || "warning";
  if (level !== "error" && level !== "warning" && level !== "info") {
    throw new Error("Invalid level. Available levels are 'error', 'warning', and 'info'.");
  }
  const maxCustomValidationConcurrency = flags["max-custom-validation-concurrency"];
  if (maxCustomValidationConcurrency && typeof maxCustomValidationConcurrency !== "number" && !Number.isInteger(maxCustomValidationConcurrency)) {
    throw new Error("'--max-custom-validation-concurrency' must be an integer.");
  }
  const clientConfig = {
    ...apiClient({
      requireUser: true,
      requireProject: false
      // we'll get this from the workspace
    }).config(),
    // we set this explictly to true because the default client configuration
    // from the CLI comes configured with `useProjectHostname: false` when
    // `requireProject` is set to false
    useProjectHostname: true,
    // we set this explictly to true because we pass in a token via the
    // `clientConfiguration` object and also mock a browser environment in
    // this worker which triggers the browser warning
    ignoreBrowserTokenWarning: true
  };
  let ndjsonFilePath;
  if (flags.file) {
    if (typeof flags.file !== "string") {
      throw new Error("'--file' must be a string");
    }
    const filePath = path__default.default.resolve(workDir, flags.file);
    const stat = await fs__default.default.promises.stat(filePath);
    if (!stat.isFile()) {
      throw new Error("'--file' must point to a valid ndjson file or tarball");
    }
    ndjsonFilePath = filePath;
  }
  const overallLevel = await validateDocuments({
    workspace: flags.workspace,
    dataset: flags.dataset,
    clientConfig,
    workDir,
    level,
    maxCustomValidationConcurrency,
    ndjsonFilePath,
    reporter: worker => {
      const reporter = flags.format && flags.format in reporters ? reporters[flags.format] : reporters.pretty;
      return reporter({
        output,
        worker,
        flags
      });
    }
  });
  process.exitCode = overallLevel === "error" ? 1 : 0;
}
exports.default = validateAction;
//# sourceMappingURL=validateAction-CEWLllLc.js.map
